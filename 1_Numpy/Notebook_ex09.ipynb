{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-13 20:14:52--  https://raw.githubusercontent.com/01-edu/public/master/subjects/ai/numpy/data/model_forecasts.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2335 (2.3K) [text/plain]\n",
      "Saving to: ‘./data/model_forecasts.txt’\n",
      "\n",
      "model_forecasts.txt 100%[===================>]   2.28K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-10-13 20:14:52 (6.69 MB/s) - ‘./data/model_forecasts.txt’ saved [2335/2335]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "folder = 'data'\n",
    "file_to_download = folder+'/model_forecasts.txt'\n",
    "\n",
    "# Check if foder exists\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "    \n",
    "# Check if the file exists\n",
    "if not os.path.exists(file_to_download):\n",
    "    # If the file doesn't exist, download it\n",
    "    ! wget -P ./data https://raw.githubusercontent.com/01-edu/public/master/subjects/ai/numpy/data/model_forecasts.txt\n",
    "else:\n",
    "    print(f\"{file_to_download} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 6, 7, 8],\n",
       "       [9, 5, 0, 4, 1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from the model_forecasts.txt file into a NumPy array\n",
    "score_diff_matrix = np.loadtxt(file_to_download)\n",
    "\n",
    "# Display the score difference matrix to verify that it has been loaded correctly\n",
    "score_diff_matrix\n",
    "\n",
    "# Generate all permutations of 10 teams\n",
    "all_permutations = list(permutations(range(10)))\n",
    "\n",
    "# Initialize variable to store the minimum sum of squared differences and the best pairing\n",
    "min_sum_squared_diffs = float('inf')\n",
    "best_pairing = None\n",
    "\n",
    "def calculate_sum_squared_diffs(perm):\n",
    "    team_set1 = perm[:5]\n",
    "    team_set2 = perm[5:]\n",
    "    squared_diffs = np.square([score_diff_matrix[i, j] for i, j in zip(team_set1, team_set2)])\n",
    "    return np.sum(squared_diffs), (team_set1, team_set2)\n",
    "\n",
    "# Use map to apply the calculate_sum_squared_diffs function to all permutations\n",
    "results = map(calculate_sum_squared_diffs, all_permutations)\n",
    "\n",
    "# Use min to find the best pairing\n",
    "min_sum_squared_diffs, best_pairing = min(results)\n",
    "\n",
    "result = [list(pair) for pair in zip(best_pairing[0],best_pairing[1])]\n",
    "result_np = np.array(result)\n",
    "\n",
    "# Extract the first and second elements from each sublist\n",
    "first_elements = result_np[:, 0]\n",
    "second_elements = result_np[:, 1]\n",
    "\n",
    "# Construct the wanted_result\n",
    "wanted_result = np.vstack([first_elements, second_elements])    \n",
    "wanted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
